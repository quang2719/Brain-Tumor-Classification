{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I try different models to compare with my original model. However, the approach I used has some errors, so the output is just for reference. As my teacher recommended, when trying to use other models for this task, I need to use other techniques such as transfer learning or fine-tuning (which I have done in the nb4 notebook). You can check this notebook for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.utils import normalize\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dir = os.listdir('./data_no/data_no/NO/')\n",
    "yes_dir = os.listdir('./data_yes/data_yes/YES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set,label = [],[]\n",
    "for i,cur_img_dir in enumerate(no_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_no/data_no/NO/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,cur_img_dir in enumerate(yes_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_yes/data_yes/YES/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092, 64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = np.array(data_set)\n",
    "label = np.array(label)\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes observe:557, no observe:535\n"
     ]
    }
   ],
   "source": [
    "print(f'yes observe:{sum(label)}, no observe:{len(label)-sum(label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and normalize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    data_set,label,\n",
    "    test_size=0.2,\n",
    "    random_state=99\n",
    "    )\n",
    "x_train,x_val,y_train,y_val = train_test_split(\n",
    "        x_train,y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=99\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (654, 64, 64, 3)\n",
      "Y train shape: (654,)\n",
      "X test shape: (219, 64, 64, 3)\n",
      "Y test shape: (219,)\n",
      "X validation shape: (219, 64, 64, 3)\n",
      "Y validation shape: (219, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {x_train.shape}\\nY train shape: {y_train.shape}\\nX test shape: {x_test.shape}\\nY test shape: {y_test.shape}\\nX validation shape: {x_val.shape}\\nY validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, axis=1)\n",
    "x_test = normalize(x_test, axis=1)\n",
    "x_val = normalize(x_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_original_model():\n",
    "    model=Sequential()\n",
    "    INPUT_SIZE = 64\n",
    "\n",
    "    model.add(Conv2D(32,(3,3), input_shape=(INPUT_SIZE,INPUT_SIZE,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), kernel_initializer='he_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), kernel_initializer='he_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try other network to choose the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_lenet5():\n",
    "    model = Sequential([\n",
    "        Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(INPUT_SIZE, INPUT_SIZE, 3)),\n",
    "        AveragePooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(16, kernel_size=(5, 5), activation='tanh'),\n",
    "        AveragePooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation='tanh'),\n",
    "        Dense(84, activation='tanh'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_alexnet():\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=(INPUT_SIZE, INPUT_SIZE, 3)),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),  # Adjusted pooling size\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_mobilenet():\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, x_train, y_train, x_val, y_val):\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(amsgrad=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=16,\n",
    "        verbose=1,\n",
    "        epochs=10,\n",
    "        validation_data=(x_val, y_val),\n",
    "        shuffle=True\n",
    "    )\n",
    "    loss, accuracy = model.evaluate(x_val, y_val)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6244\\4043771889.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('Original', create_original_model()),\n",
    "    ('LeNet-5', create_lenet5()),\n",
    "    ('AlexNet', create_alexnet()),\n",
    "    ('MobileNet', create_mobilenet()),\n",
    "]\n",
    "accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.5216 - loss: 0.6982 - val_accuracy: 0.7854 - val_loss: 0.6442\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6633 - loss: 0.6210 - val_accuracy: 0.8037 - val_loss: 0.4523\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7485 - loss: 0.5017 - val_accuracy: 0.8219 - val_loss: 0.3665\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8241 - loss: 0.3939 - val_accuracy: 0.8721 - val_loss: 0.3188\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8777 - loss: 0.2986 - val_accuracy: 0.9178 - val_loss: 0.2247\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9211 - loss: 0.2055 - val_accuracy: 0.9406 - val_loss: 0.1750\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9510 - loss: 0.1606 - val_accuracy: 0.9178 - val_loss: 0.2048\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0885 - val_accuracy: 0.8402 - val_loss: 0.3055\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9444 - loss: 0.1373 - val_accuracy: 0.9452 - val_loss: 0.1564\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9762 - loss: 0.0877 - val_accuracy: 0.9498 - val_loss: 0.1199\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9433 - loss: 0.1286\n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5836 - loss: 0.6703 - val_accuracy: 0.6986 - val_loss: 0.6043\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7698 - loss: 0.4675 - val_accuracy: 0.8037 - val_loss: 0.3909\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8621 - loss: 0.3137 - val_accuracy: 0.8174 - val_loss: 0.3722\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8641 - loss: 0.2840 - val_accuracy: 0.8219 - val_loss: 0.4515\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8917 - loss: 0.2690 - val_accuracy: 0.8539 - val_loss: 0.3394\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9202 - loss: 0.2173 - val_accuracy: 0.8493 - val_loss: 0.3752\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9347 - loss: 0.1880 - val_accuracy: 0.8539 - val_loss: 0.4006\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9228 - loss: 0.1816 - val_accuracy: 0.8539 - val_loss: 0.4253\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9368 - loss: 0.1601 - val_accuracy: 0.8539 - val_loss: 0.5076\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9382 - loss: 0.1811 - val_accuracy: 0.8630 - val_loss: 0.4157\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.4196 \n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.5830 - loss: 0.8337 - val_accuracy: 0.5251 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 375ms/step - accuracy: 0.5292 - loss: 0.6933 - val_accuracy: 0.4749 - val_loss: 0.6949\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 376ms/step - accuracy: 0.5095 - loss: 0.6922 - val_accuracy: 0.4749 - val_loss: 0.6944\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 373ms/step - accuracy: 0.5118 - loss: 0.6931 - val_accuracy: 0.4749 - val_loss: 0.6953\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 375ms/step - accuracy: 0.5179 - loss: 0.6935 - val_accuracy: 0.4749 - val_loss: 0.6966\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 373ms/step - accuracy: 0.5472 - loss: 0.6900 - val_accuracy: 0.4749 - val_loss: 0.6957\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 371ms/step - accuracy: 0.5060 - loss: 0.6939 - val_accuracy: 0.4749 - val_loss: 0.6955\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 392ms/step - accuracy: 0.4935 - loss: 0.6954 - val_accuracy: 0.4749 - val_loss: 0.6953\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - accuracy: 0.4983 - loss: 0.6944 - val_accuracy: 0.4749 - val_loss: 0.6972\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 404ms/step - accuracy: 0.5021 - loss: 0.6940 - val_accuracy: 0.4749 - val_loss: 0.6966\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4674 - loss: 0.6973\n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 282ms/step - accuracy: 0.7504 - loss: 1.6733 - val_accuracy: 0.9269 - val_loss: 0.2361\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.9503 - loss: 0.1256 - val_accuracy: 0.6758 - val_loss: 0.9953\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9214 - loss: 0.1908 - val_accuracy: 0.9087 - val_loss: 0.2355\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 224ms/step - accuracy: 0.9529 - loss: 0.1636 - val_accuracy: 0.8767 - val_loss: 0.3471\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9846 - loss: 0.0520 - val_accuracy: 0.6393 - val_loss: 2.3191\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.9579 - loss: 0.1066 - val_accuracy: 0.8174 - val_loss: 0.3855\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.9726 - loss: 0.1206 - val_accuracy: 0.9224 - val_loss: 0.2205\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 257ms/step - accuracy: 0.9731 - loss: 0.0746 - val_accuracy: 0.8858 - val_loss: 0.3871\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.9854 - loss: 0.0510 - val_accuracy: 0.9269 - val_loss: 0.1806\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 227ms/step - accuracy: 0.9707 - loss: 0.0675 - val_accuracy: 0.9132 - val_loss: 0.4279\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9199 - loss: 0.5434\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    accuracy = compile_and_train(model, x_train, y_train, x_val, y_val)\n",
    "    accuracies.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print accuracy of all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of models sorted by accuracy\n",
      "Model: Original, Accuracy: 0.9497717022895813\n",
      "Model: MobileNet, Accuracy: 0.913241982460022\n",
      "Model: LeNet-5, Accuracy: 0.8630136847496033\n",
      "Model: AlexNet, Accuracy: 0.47488585114479065\n",
      "Best Model: Original, Accuracy: 0.9497717022895813\n"
     ]
    }
   ],
   "source": [
    "# Sort models by accuracy in descending order\n",
    "accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print models and their accuracies\n",
    "print(\"list of models sorted by accuracy\")\n",
    "for name, accuracy in accuracies:\n",
    "    print(f'Model: {name}, Accuracy: {accuracy}')\n",
    "\n",
    "# Choose the model with the highest accuracy\n",
    "best_model_name, best_accuracy = accuracies[0]\n",
    "print(f'Best Model: {best_model_name}, Accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, the original model is the best!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
