{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.utils import normalize\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid difference result after rerun notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dir = os.listdir('./data_no/data_no/NO/')\n",
    "yes_dir = os.listdir('./data_yes/data_yes/YES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set,label = [],[]\n",
    "for i,cur_img_dir in enumerate(no_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_no/data_no/NO/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,cur_img_dir in enumerate(yes_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_yes/data_yes/YES/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = np.array(data_set)\n",
    "label = np.array(label)\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes observe:557, no observe:535\n"
     ]
    }
   ],
   "source": [
    "print(f'yes observe:{sum(label)}, no observe:{len(label)-sum(label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and normalize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    data_set,label,\n",
    "    test_size=0.2,\n",
    "    random_state=99\n",
    "    )\n",
    "x_train,x_val,y_train,y_val = train_test_split(\n",
    "        x_train,y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=99\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (654, 64, 64, 3)\n",
      "Y train shape: (654,)\n",
      "X test shape: (219, 64, 64, 3)\n",
      "Y test shape: (219,)\n",
      "X validation shape: (219, 64, 64, 3)\n",
      "Y validation shape: (219, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {x_train.shape}\\nY train shape: {y_train.shape}\\nX test shape: {x_test.shape}\\nY test shape: {y_test.shape}\\nX validation shape: {x_val.shape}\\nY validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, axis=1)\n",
    "x_test = normalize(x_test, axis=1)\n",
    "x_val = normalize(x_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape=(INPUT_SIZE,INPUT_SIZE,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom F1 score metric\n",
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5359 - f1_score: 8.2010 - false_negatives: 52.0250 - false_positives: 93.4000 - loss: 0.6955 - true_negatives: 63.7750 - true_positives: 118.8000\n",
      "Epoch 1: saving model to /model\\weights-improvement-01-9.47.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.5380 - f1_score: 8.2148 - false_negatives: 54.0714 - false_positives: 97.5238 - loss: 0.6947 - true_negatives: 67.1190 - true_positives: 124.8095 - val_accuracy: 0.6164 - val_f1_score: 9.4681 - val_false_negatives: 1.0000 - val_false_positives: 83.0000 - val_loss: 0.6315 - val_true_negatives: 32.0000 - val_true_positives: 103.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7060 - f1_score: 8.5159 - false_negatives: 42.6000 - false_positives: 51.3250 - loss: 0.5771 - true_negatives: 105.8500 - true_positives: 128.2250\n",
      "Epoch 2: saving model to /model\\weights-improvement-02-7.70.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7063 - f1_score: 8.4976 - false_negatives: 44.6190 - false_positives: 53.8333 - loss: 0.5768 - true_negatives: 110.8095 - true_positives: 134.2619 - val_accuracy: 0.7991 - val_f1_score: 7.6999 - val_false_negatives: 17.0000 - val_false_positives: 27.0000 - val_loss: 0.4803 - val_true_negatives: 88.0000 - val_true_positives: 87.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8213 - f1_score: 8.1400 - false_negatives: 31.2051 - false_positives: 26.3846 - loss: 0.4348 - true_negatives: 126.9231 - true_positives: 135.4872\n",
      "Epoch 3: saving model to /model\\weights-improvement-03-7.20.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8203 - f1_score: 8.1359 - false_negatives: 33.3333 - false_positives: 29.0238 - loss: 0.4349 - true_negatives: 135.6190 - true_positives: 145.5476 - val_accuracy: 0.8219 - val_f1_score: 7.1963 - val_false_negatives: 22.0000 - val_false_positives: 17.0000 - val_loss: 0.4054 - val_true_negatives: 98.0000 - val_true_positives: 82.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8650 - f1_score: 7.9808 - false_negatives: 24.2051 - false_positives: 17.6923 - loss: 0.3424 - true_negatives: 135.6154 - true_positives: 142.4872\n",
      "Epoch 4: saving model to /model\\weights-improvement-04-7.49.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8655 - f1_score: 7.9852 - false_negatives: 25.6905 - false_positives: 19.0952 - loss: 0.3407 - true_negatives: 145.5476 - true_positives: 153.1905 - val_accuracy: 0.9041 - val_f1_score: 7.4948 - val_false_negatives: 9.0000 - val_false_positives: 12.0000 - val_loss: 0.2876 - val_true_negatives: 103.0000 - val_true_positives: 95.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9013 - f1_score: 8.2131 - false_negatives: 16.8537 - false_positives: 14.0244 - loss: 0.2474 - true_negatives: 146.9756 - true_positives: 158.0976\n",
      "Epoch 5: saving model to /model\\weights-improvement-05-7.39.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9015 - f1_score: 8.2116 - false_negatives: 17.2143 - false_positives: 14.3333 - loss: 0.2471 - true_negatives: 150.3095 - true_positives: 161.6667 - val_accuracy: 0.9178 - val_f1_score: 7.3892 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_loss: 0.2212 - val_true_negatives: 106.0000 - val_true_positives: 95.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9317 - f1_score: 8.3165 - false_negatives: 11.0244 - false_positives: 9.6829 - loss: 0.1850 - true_negatives: 151.3171 - true_positives: 163.9268\n",
      "Epoch 6: saving model to /model\\weights-improvement-06-7.64.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9319 - f1_score: 8.3144 - false_negatives: 11.2381 - false_positives: 9.8810 - loss: 0.1848 - true_negatives: 154.7619 - true_positives: 167.6429 - val_accuracy: 0.9224 - val_f1_score: 7.6442 - val_false_negatives: 5.0000 - val_false_positives: 12.0000 - val_loss: 0.1974 - val_true_negatives: 103.0000 - val_true_positives: 99.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9583 - f1_score: 8.4145 - false_negatives: 6.0750 - false_positives: 6.0250 - loss: 0.1241 - true_negatives: 151.1500 - true_positives: 164.7500\n",
      "Epoch 7: saving model to /model\\weights-improvement-07-7.09.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9587 - f1_score: 8.4066 - false_negatives: 6.3571 - false_positives: 6.2143 - loss: 0.1238 - true_negatives: 158.4286 - true_positives: 172.5238 - val_accuracy: 0.9361 - val_f1_score: 7.0866 - val_false_negatives: 11.0000 - val_false_positives: 3.0000 - val_loss: 0.1628 - val_true_negatives: 112.0000 - val_true_positives: 93.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9607 - f1_score: 8.2309 - false_negatives: 8.6500 - false_positives: 4.3250 - loss: 0.1054 - true_negatives: 152.8500 - true_positives: 162.1750\n",
      "Epoch 8: saving model to /model\\weights-improvement-08-7.45.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9607 - f1_score: 8.2287 - false_negatives: 9.0000 - false_positives: 4.5476 - loss: 0.1057 - true_negatives: 160.0952 - true_positives: 169.8810 - val_accuracy: 0.9680 - val_f1_score: 7.4521 - val_false_negatives: 3.0000 - val_false_positives: 4.0000 - val_loss: 0.1364 - val_true_negatives: 111.0000 - val_true_positives: 101.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9715 - f1_score: 8.3377 - false_negatives: 6.0244 - false_positives: 3.2927 - loss: 0.0739 - true_negatives: 157.7073 - true_positives: 168.9268\n",
      "Epoch 9: saving model to /model\\weights-improvement-09-7.05.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9715 - f1_score: 8.3353 - false_negatives: 6.1429 - false_positives: 3.4048 - loss: 0.0740 - true_negatives: 161.2381 - true_positives: 172.7381 - val_accuracy: 0.9406 - val_f1_score: 7.0490 - val_false_negatives: 11.0000 - val_false_positives: 2.0000 - val_loss: 0.1476 - val_true_negatives: 113.0000 - val_true_positives: 93.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9858 - f1_score: 8.3688 - false_negatives: 2.6250 - false_positives: 2.1000 - loss: 0.0667 - true_negatives: 155.0750 - true_positives: 168.2000\n",
      "Epoch 10: saving model to /model\\weights-improvement-10-7.45.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9856 - f1_score: 8.3648 - false_negatives: 2.7857 - false_positives: 2.2857 - loss: 0.0669 - true_negatives: 162.3571 - true_positives: 176.0952 - val_accuracy: 0.9589 - val_f1_score: 7.4457 - val_false_negatives: 4.0000 - val_false_positives: 5.0000 - val_loss: 0.1221 - val_true_negatives: 110.0000 - val_true_positives: 100.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(amsgrad=True), \n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model checkpoints\n",
    "filepath = \"weights-improvement-{epoch:02d}-{val_f1_score:.2f}.weights.h5\"\n",
    "savemodel = '/model' \n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(savemodel, filepath),\n",
    "    monitor='val_f1_score',\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "# Ensure y_train and y_val are of type float32\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "\n",
    "# Fit model\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=False,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "(219, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_test_pred >0.5).astype(int)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_reshape = y_test.reshape(-1,1)\n",
    "y_test_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in test set: 0.9406392694063926\n",
      "Accuracy in validation set: 0.9589040875434875\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy in test set:\", accuracy_score(y_test_reshape, y_pred))\n",
    "print('Accuracy in validation set:',history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save original model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Infor**<br>\n",
    "Accuracy in test set: 0.9406392694063926\n",
    "Accuracy in validation set: 0.9589040875434875\n",
    "Name: BrainTurmor_v2<br>\n",
    "\n",
    "Status: Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BrainTurmor_v1.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
