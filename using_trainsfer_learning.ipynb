{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning, finetune VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\". It is one of the most popular pre-trained models for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Features of VGG16\n",
    "1. Architecture: VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".<br>\n",
    "2. Layers: It has 16 layers with learnable weights, including 13 convolutional layers and 3 fully connected layers.<br>\n",
    "3. Pre-trained Weights: The model is pre-trained on the ImageNet dataset, which contains 1.2 million images and 1000 classes.<br>\n",
    "4. Usage: It is widely used for image classification tasks and can be fine-tuned for specific tasks such as brain tumor classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finetune VGG16 for brain tumor classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.utils import normalize\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and nomalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dir = os.listdir('./data_no/data_no/NO/')\n",
    "yes_dir = os.listdir('./data_yes/data_yes/YES/')\n",
    "data_set,label = [],[]\n",
    "for i,cur_img_dir in enumerate(no_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_no/data_no/NO/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(0)\n",
    "for i,cur_img_dir in enumerate(yes_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./data_yes/data_yes/YES/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        data_set.append(np.array(img))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.array(data_set)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    data_set,label,\n",
    "    test_size=0.2,\n",
    "    random_state=99\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (873, 64, 64, 3)\n",
      "Y train shape: (873,)\n",
      "X test shape: (219, 64, 64, 3)\n",
      "Y test shape: (219,))\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {x_train.shape}\\nY train shape: {y_train.shape}\\nX test shape: {x_test.shape}\\nY test shape: {y_test.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, axis=1)\n",
    "x_test = normalize(x_test, axis=1)\n",
    "x_val = normalize(x_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model with pre-trained weights, excluding the top fully connected layers\n",
    "base_model = VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(64, 64, 3)\n",
    "    )\n",
    "\n",
    "# Freeze the convolutional base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom top layers for classification\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x) #binary classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 21s 677ms/step - loss: 1.4543 - accuracy: 0.8110 - val_loss: 0.2840 - val_accuracy: 0.9315\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 18s 644ms/step - loss: 0.2645 - accuracy: 0.9278 - val_loss: 0.4195 - val_accuracy: 0.8995\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 18s 648ms/step - loss: 0.2449 - accuracy: 0.9313 - val_loss: 0.1887 - val_accuracy: 0.9452\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 19s 681ms/step - loss: 0.1121 - accuracy: 0.9668 - val_loss: 0.2459 - val_accuracy: 0.9132\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 18s 660ms/step - loss: 0.0819 - accuracy: 0.9668 - val_loss: 0.1638 - val_accuracy: 0.9498\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 19s 695ms/step - loss: 0.0351 - accuracy: 0.9851 - val_loss: 0.1756 - val_accuracy: 0.9452\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 20s 726ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.3485 - val_accuracy: 0.9041\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 19s 687ms/step - loss: 0.0665 - accuracy: 0.9828 - val_loss: 0.9019 - val_accuracy: 0.8402\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 19s 678ms/step - loss: 0.6062 - accuracy: 0.8866 - val_loss: 0.2093 - val_accuracy: 0.9406\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 20s 733ms/step - loss: 0.1878 - accuracy: 0.9599 - val_loss: 0.2873 - val_accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=1e-4, amsgrad=True),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_data = (x_test, y_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
